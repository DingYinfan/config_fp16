[
	  {
        "model_name": "Qwen-1_8B-Chat-bf16",
        "args": "--model=Qwen-1_8B-Chat --device=cuda --dtype=bfloat16 --max-model-len=2048 --dataset=./llm_samples_new/qwen/Qwen-1_8B-Chat.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen-1_8B-Chat.json --trust-remote-code"
    },

    {
        "model_name": "Qwen-7B",
        "args": "--model=Qwen-7B --device=cuda  --max-model-len=2048 --dtype=float16 --dataset=./llm_samples_new/qwen/Qwen-7B-half.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen-7B-half.json --trust-remote-code"
    },

	  {
        "model_name": "Qwen-7B-Chat-bf16",
        "args": "--model=Qwen-7B-Chat --device=cuda  --max-model-len=2048 --dtype=bfloat16 --dataset=./llm_samples_new/qwen/qwen_7b_chat.json --tensor-parallel-size=1 --save-output=./output/qwen/qwen_7b_chat.json --trust-remote-code"
    },

	  {
        "model_name": "Qwen-14B-Chat-fp16",
        "args": "--model=Qwen-14B-Chat --device=cuda  --max-model-len=2048 --dtype=float16 --dataset=./llm_samples_new/qwen/Qwen-14B-chat-half.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen-14B-chat-half.json --trust-remote-code"
    },

	  {
        "model_name": "Qwen-14B-Chat-bf16",
        "args": "--model=Qwen-14B-Chat --device=cuda  --max-model-len=2048 --dtype=bfloat16 --dataset=./llm_samples_new/qwen/qwen_14b_chat.json --tensor-parallel-size=1 --save-output=./output/qwen/qwen_14b_chat.json --trust-remote-code"
    },

 	  {
        "model_name": "Qwen-72B-Chat-fp16",
        "args": "--model=Qwen-72B-Chat --device=cuda  --max-model-len=2048 --dtype=float16 --dataset=./llm_samples_new/qwen/Qwen-72B-chat-half.json --tensor-parallel-size=4 --save-output=./output/qwen/Qwen-72B-chat-half.json --trust-remote-code"
    },

 	  {
        "model_name": "Qwen-72B-Chat-bf16",
        "args": "--model=Qwen-72B-Chat --device=cuda  --max-model-len=2048 --dtype=bfloat16 --dataset=./llm_samples_new/qwen/qwen_72b_chat.json --tensor-parallel-size=4 --save-output=./output/qwen/qwen_72b_chat.json --trust-remote-code"
    },

    {
        "model_name": "Qwen1.5-7B",
        "args": "--model=Qwen1.5-7B --device=cuda --dtype=float16 --max-model-len=2048 --dataset=./llm_samples_new/qwen/Qwen1.5-7B-half.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen1.5-7B-half.json"
    },

    {
        "model_name": "Qwen1.5-14B-Chat",
        "args": "--model=Qwen1.5-14B-Chat --device=cuda --dtype=float16 --max-model-len=2048 --dataset=./llm_samples_new/qwen/Qwen1.5-14B-Chat-half.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen1.5-14B-Chat-half.json"
    },

	  {
        "model_name": "Qwen1.5-32B",
        "args": "--model=Qwen1.5-32B --device=cuda  --max-model-len=2048 --dtype=float16 --dataset=./llm_samples_new/qwen/Qwen1.5-32B-half.json --tensor-parallel-size=2 --save-output=./output/qwen/Qwen1.5-32B-half.json --trust-remote-code"
    },

    {
        "model_name": "Qwen1.5-72B-Chat",
        "args": "--model=Qwen1.5-72B-Chat --device=cuda --dtype=float16 --max-model-len=2048 --dataset=./llm_samples_new/qwen/Qwen1.5-72B-Chat-half.json --tensor-parallel-size=4 --save-output=./output/qwen/Qwen1.5-72B-Chat-half.json"
    },

    {
        "model_name": "qwen1.5-4b-chat-bf16",
        "args": "--model=qwen1.5-4b-chat --device=cuda --dataset=./llm_samples_new/qwen/Qwen1.5-4B-Chat-auto.json --dtype=bfloat16 --max-model-len=32768 --tensor-parallel-size=1 --save-output=./output/qwen/Qwen1.5-4B-Chat-auto.json"
    },

    {
        "model_name": "qwen1.5-4b-bf16",
        "args": "--model=qwen1.5-4b --device=cuda --dataset=./llm_samples_new/qwen/Qwen1.5-4B-auto.json --dtype=bfloat16 --max-model-len=32768 --tensor-parallel-size=1 --save-output=./output/qwen/Qwen1.5-4B-auto.json"
    },

    {
        "model_name": "Qwen1.5-MoE-A2.7B-bf16",
        "args": "--model=Qwen1.5-MoE-A2.7B --device=cuda --dtype=bfloat16 --max-model-len=4096 --dataset=./llm_samples_new/qwen/Qwen1.5-MoE-A2.7B-bfloat16-golden.json --save-output=./output/qwen/Qwen1.5-MoE-A2.7B-bfloat16-golden.json"
    },
	
    {
        "model_name": "qwen1.5_32b_w4a16_gptq",
        "args": "--model=qwen1.5_32b_w4a16_gptq --device=cuda --dtype=float16 --max-model-len=4096 --dataset=./llm_samples_new/qwen/qwen1.5-32b-w4a16-gptq.json --quantization gptq --save-output=./output/qwen/qwen1.5-32b-w4a16-gptq.json"
    },
 
    {
        "model_name": "qwen2-0.5b-instruct-bf16",
        "args": "--model=qwen2-0.5b-instruct --device=cuda --dtype=bfloat16 --max-model-len=32768 --dataset=./llm_samples_new/qwen/Qwen2-0.5B-Instruct-bfloat16.json --tensor-parallel-size=1 --gpu-memory-utilization=0.945 --save-output=./output/qwen/Qwen2-0.5B-Instruct-bfloat16.json"
    },

    {
        "model_name": "Qwen2-1.5B-Instruct-bf16",
        "args": "--model=Qwen2-1.5B-Instruct --device=cuda --dataset=./llm_samples_new/qwen/Qwen2-1.5B-Instruct-bfloat16.json --dtype=bfloat16 --max-model-len=32768 --tensor-parallel-size=1 --save-output=./output/qwen/Qwen2-1.5B-Instruct-bfloat16.json"
    },

    {
        "model_name": "Qwen2-1.5B-Instruct",
        "args": "--model=Qwen2-1.5B-Instruct --device=cuda --dataset=./llm_samples_new/qwen/Qwen2-1.5B-Instruct-float16.json --dtype=float16 --max-model-len=32768 --output-len=128 --save-output=./output/qwen/Qwen2-1.5B-Instruct-float16.json"
    },

    {
        "model_name": "Qwen2-7B",
        "args": "--model=Qwen2-7B --device=cuda --dtype=float16 --max-model-len=32768 --dataset=./llm_samples_new/qwen/Qwen2-7B-float16.json --tensor-parallel-size=1 --gpu-memory-utilization=0.945 --save-output=./output/qwen/Qwen2-7B-float16.json"
    },

    {
        "model_name": "qwen2-7b-instruct-bf16",
        "args": "--model=qwen2-7b-instruct --device cuda --dtype=bfloat16 --max-model-len=32768 --dataset=./llm_samples_new/qwen/Qwen2-7B-Instruct-bfloat16.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen2-7B-Instruct-bfloat16.json"
    },

    {
        "model_name": "qwen_14b_chat_w8a16_gptq",
        "args": "--model=qwen_14b_chat_w8a16_gptq --device=cuda --dtype=float16 --max-model-len 2048 --quantization=gptq --dataset=./llm_samples_new/qwen/Qwen-14B-Chat_w8a16.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen-14B-Chat_w8a16.json --trust-remote-code"
    },
	
    {
        "model_name": "qwen_72b_chat_w8a16_gptq",
        "args": "--model=qwen_72b_chat_w8a16_gptq --device=cuda --dtype=float16 --max-model-len 2048 --quantization=gptq --dataset=./llm_samples_new/qwen/Qwen-72B-Chat_w8a16.json --tensor-parallel-size=4 --save-output=./output/qwen/Qwen-72B-Chat_w8a16.json --trust-remote-code"
    },
    
    {
        "model_name": "qwen1.5_32b_w8a16_gptq",
        "args": "--model=qwen1.5_32b_w8a16_gptq --device=cuda  --max-model-len=4096 --quantization=gptq --dtype=float16 --dataset=./llm_samples_new/qwen/Qwen1.5-32B-quant-float16-w8a16.json --tensor-parallel-size=1 --save-output=./output/qwen/Qwen1.5-32B-quant-float16-w8a16.json"
    }
]
