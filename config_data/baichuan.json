[
    {
        "model_name": "Baichuan2-13B-Base",
        "args": "--vllm-path=Baichuan2-13B-Base --device=cuda --datasets=mmlu_gen --data-dir=tinydata/mmlu --work-dir=outputs/Baichuan2-13B-Base --tensor-parallel-size=1 --model-kwargs dtype=float16 gpu_memory_utilization=0.8"
    },

    {
        "model_name": "baichuan2_7b_w8a16_gptq",
        "args": "--vllm-path=baichuan2_7b_w8a16_gptq --device=cuda --datasets=mmlu_gen --data-dir=tinydata/mmlu --work-dir=outputs/baichuan2_7b_w8a16_gptq --tensor-parallel-size=1 --model-kwargs dtype=float16 quantization=gptq"
    },
	
    {
        "model_name": "baichuan2_13b_w8a16_gptq",
        "args": "--vllm-path=baichuan2_13b_w8a16_gptq --device=cuda --datasets=mmlu_gen --data-dir=tinydata/mmlu --work-dir=outputs/baichuan2_13b_w8a16_gptq --batch-size=3 --tensor-parallel-size=1 --model-kwargs dtype=float16 max_model_len=4096 quantization=gptq gpu_memory_utilization=0.75"
    }
]