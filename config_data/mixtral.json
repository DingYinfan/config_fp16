[
    {
        "model_name": "mistral-7b-v0.1",
        "args": "--vllm-path=mistral-7b-v0.1 --device=cuda --datasets=mmlu_gen --data-dir=tinydata/mmlu --work-dir=outputs/mistral-7b-v0.1 --tensor-parallel-size=1 --model-kwargs dtype=float16"
    },

    {
        "model_name": "mixtral_8x7b_w8a16_gptq",
        "args": "--vllm-path=mixtral_8x7b_w8a16_gptq --device=cuda --datasets=mmlu_gen_79e572 --data-dir=tinydata/mmlu --work-dir=outputs/mixtral_8x7b_w8a16_gptq --tensor-parallel-size=4 --model-kwargs dtype=float16 quantization=gptq"
    }
]