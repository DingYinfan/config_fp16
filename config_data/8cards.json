[	
    {
        "model_name": "mixtral-8x22b-v0.1",
        "args": "--vllm-path=mixtral-8x22b-v0.1 --device=cuda --datasets=ceval_gen --data-dir=tinydata/ceval/formal_ceval --batch-size=4 --max-out-len=10 --work-dir=outputs/mixtral-8x22b-v0.1 --tensor-parallel-size=8 --model-kwargs dtype=bfloat16 max_model_len=8192"
    },

    {
        "model_name": "dbrx-instruct-fp16",
        "args": "--vllm-path=dbrx-instruct --device=cuda --datasets=triviaqa_gen --data-dir=tinydata/triviaqa --work-dir=outputs/dbrx-instruct-fp16 --tensor-parallel-size=8 --model-kwargs dtype=float16 max_model_len=4096"
    },

    {
        "model_name": "dbrx-instruct-bf16",
        "args": "--vllm-path=dbrx-instruct --device=cuda --datasets=triviaqa_gen --data-dir=tinydata/triviaqa --work-dir=outputs/dbrx-instruct-bf16 --tensor-parallel-size=8 --model-kwargs dtype=bfloat16 max_model_len=4096"
    },

    {
        "model_name": "Meta-Llama-3.1-70B-Instruct-bf16",
        "args": "--vllm-path=Meta-Llama-3.1-70B-Instruct --device=cuda --datasets=ceval_gen --data-dir=tinydata/ceval/formal_ceval --work-dir=outputs/Meta-Llama-3.1-70B-Instruct-bf16 --tensor-parallel-size=8 --max-out-len=1 --batch-size=32 --model-kwargs dtype=bfloat16 max_model_len=32768"
    },

    {
        "model_name": "qwen1.5-72b-chat-awq",
        "args": "--vllm-path=qwen1.5-72b-chat-awq --device=cuda --datasets=ceval_gen --data-dir=tinydata/ceval/formal_ceval/ --work-dir=outputs/qwen1.5-72b-chat-awq --tensor-parallel-size=8 --max-out-len=10 --batch-size=4 --model-kwargs dtype=float16 max_model_len=32768 gpu_memory_utilization=0.945"
    },

    {
        "model_name": "qwen2-72b-instruct",
        "args": "--vllm-path=qwen2-72b-instruct --device=cuda --datasets=ceval_gen --data-dir=tinydata/ceval/formal_ceval/ --tensor-parallel-size=8 --work-dir=outputs/qwen2-72b-instruct --model-kwargs dtype=float16 --batch-size 16 --max-out-len 100"
    },

    {
        "model_name": "yi-34b-200k-bs1",
        "args": "--vllm-path=yi-34b-200k --device=cuda --datasets=longbench --data-dir=tinydata/LongBench --work-dir=outputs/yi-34b-200k-bs1 --tensor-parallel-size=8 --max-out-len=10 --model-kwargs dtype=float16  max_model_len=200000 max_num_seqs=1"
    },

    {
        "model_name": "yi-34b-200k",
        "args": "--vllm-path=yi-34b-200k --device=cuda --datasets=longbench --data-dir=tinydata/LongBench --work-dir=outputs/yi-34b-200k --tensor-parallel-size=8 --max-out-len=10 --model-kwargs dtype=float16  max_model_len=200000"
    } 
]
